{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import glob\n",
    "import math\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Loading and Graph Constructing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] File b'../data/customerinformation.csv' does not exist: b'../data/customerinformation.csv'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-2-a7dc0346c40c>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mCustInfo\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread_csv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'../data/customerinformation.csv'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mCustInfo\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'open_date'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto_datetime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mCustInfo\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mOpen_Date\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;31m# CheqTrans = pd.read_csv('../../AMLAML/chequetransaction.csv')\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;31m# CheqTrans['trans_date'] = pd.to_datetime(CheqTrans.trandt)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/lib/python3.6/site-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36mparser_f\u001b[0;34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, squeeze, prefix, mangle_dupe_cols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, skipfooter, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, dayfirst, cache_dates, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, doublequote, escapechar, comment, encoding, dialect, error_bad_lines, warn_bad_lines, delim_whitespace, low_memory, memory_map, float_precision)\u001b[0m\n\u001b[1;32m    683\u001b[0m         )\n\u001b[1;32m    684\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 685\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0m_read\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    686\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    687\u001b[0m     \u001b[0mparser_f\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__name__\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/lib/python3.6/site-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36m_read\u001b[0;34m(filepath_or_buffer, kwds)\u001b[0m\n\u001b[1;32m    455\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    456\u001b[0m     \u001b[0;31m# Create the parser.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 457\u001b[0;31m     \u001b[0mparser\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mTextFileReader\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfp_or_buf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    458\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    459\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mchunksize\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0miterator\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/lib/python3.6/site-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, f, engine, **kwds)\u001b[0m\n\u001b[1;32m    893\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptions\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"has_index_names\"\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mkwds\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"has_index_names\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    894\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 895\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_make_engine\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mengine\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    896\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    897\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mclose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/lib/python3.6/site-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36m_make_engine\u001b[0;34m(self, engine)\u001b[0m\n\u001b[1;32m   1133\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_make_engine\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mengine\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"c\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1134\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mengine\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m\"c\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1135\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_engine\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mCParserWrapper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptions\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1136\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1137\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mengine\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m\"python\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/lib/python3.6/site-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, src, **kwds)\u001b[0m\n\u001b[1;32m   1904\u001b[0m         \u001b[0mkwds\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"usecols\"\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0musecols\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1905\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1906\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_reader\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mparsers\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTextReader\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msrc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1907\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munnamed_cols\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_reader\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munnamed_cols\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1908\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/parsers.pyx\u001b[0m in \u001b[0;36mpandas._libs.parsers.TextReader.__cinit__\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/parsers.pyx\u001b[0m in \u001b[0;36mpandas._libs.parsers.TextReader._setup_parser_source\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] File b'../data/customerinformation.csv' does not exist: b'../data/customerinformation.csv'"
     ]
    }
   ],
   "source": [
    "CustInfo = pd.read_csv('../data/customerinformation.csv')\n",
    "CustInfo['open_date'] = pd.to_datetime(CustInfo.Open_Date)\n",
    "\n",
    "# CheqTrans = pd.read_csv('../../AMLAML/chequetransaction.csv')\n",
    "# CheqTrans['trans_date'] = pd.to_datetime(CheqTrans.trandt)\n",
    "\n",
    "# SARCase = pd.read_csv('../data/sarcase.csv')\n",
    "# SARCase['created_date'] = pd.to_datetime(SARCase.Created_Date)\n",
    "\n",
    "WireTrans = pd.read_csv('../data/new_wire.csv', index_col=0)\n",
    "WireTrans['trans_date'] = pd.to_datetime(WireTrans.trandt)\n",
    "# WireTrans = WireTrans.drop('Unnamed: 0', axis=1)\n",
    "#WireTrans.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# delete Non-IBW Customer_Segment_Code customerno\n",
    "new_wire = WireTrans[WireTrans.customerno.isin(CustInfo[CustInfo.Customer_Segment_Code != 'IBW']['customerno'].values)]\n",
    "\n",
    "# According Trf_Direction to build new feature  \n",
    "new_wire['bnf_cust'] = new_wire.apply(lambda x: x['customerno'] if x['Trf_Direction'] == 'I' else np.nan ,axis=1)\n",
    "\n",
    "new_wire['org_cust'] = new_wire.apply(lambda x: x['customerno'] if x['Trf_Direction'] == 'O' else np.nan ,axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DateYM:\n",
    "    def __init__(self, year, month):\n",
    "        self.year = year\n",
    "        self.month = month - 1    # 0 ~ 11, from Jan to Dec\n",
    "        \n",
    "    def export_tuple(self):\n",
    "        return (self.year, self.month+1)\n",
    "    \n",
    "    def add_year(self, y):\n",
    "        self.year += y\n",
    "        \n",
    "    def substract_year(self, y):\n",
    "        self.year -= y\n",
    "        \n",
    "    def add_month(self, m):\n",
    "        self.month += m\n",
    "        self.year += math.floor(self.month / 12)\n",
    "        self.month = self.month % 12\n",
    "        \n",
    "    def subtract_month(self, m):\n",
    "        self.month -= m\n",
    "        tmp_year = math.floor(self.month / 12)\n",
    "        self.year += tmp_year\n",
    "        self.month += -tmp_year * 12\n",
    "        \n",
    "    def is_larger_than(self, ym):\n",
    "        return self.year*12 + self.month > ym.year*12 + ym.month\n",
    "    \n",
    "    def is_smaller_than(slef, ym):\n",
    "        return self.year*12 + self.month < ym.year*12 + ym.month\n",
    "    \n",
    "    def is_equal(self, ym):\n",
    "        return self.year*12 + self.month == ym.year*12 + ym.month\n",
    "\n",
    "    \n",
    "def list_date_tuples(from_date, to_date):\n",
    "    ret = []\n",
    "    tmp_date = DateYM(*from_date.export_tuple())\n",
    "    while not tmp_date.is_larger_than(to_date):\n",
    "        ret.append(tmp_date.export_tuple())\n",
    "        tmp_date.add_month(1)\n",
    "    return ret\n",
    "\n",
    "\n",
    "def fetch_data_by_month(date_ym, trans_offset=6):\n",
    "    year, month = date_ym\n",
    "    \n",
    "    from_date = pd.to_datetime(\"{}/{}/{}\".format(month, 1, year))\n",
    "    to_date = from_date + pd.DateOffset(months=1)\n",
    "    offset_date = from_date - pd.DateOffset(months=trans_offset)\n",
    "    \n",
    "    # Get view: WireTrans\n",
    "    view_wiretrans = WireTrans[(WireTrans.trans_date > offset_date) & \n",
    "                               (WireTrans.trans_date < to_date)]\n",
    "    # Get view: CheqTrans\n",
    "    # view_cheqtrans = CheqTrans[(CheqTrans.trans_date > offset_date) & \n",
    "    #                            (CheqTrans.trans_date < to_date)]    \n",
    "\n",
    "    # Get view: CustInfo\n",
    "    view_customer = CustInfo[CustInfo.open_date < to_date]\n",
    "    \n",
    "    # Attach label onto CustInfo\n",
    "    target_list = SARCase[(SARCase.Status_SAR == 4) & \n",
    "                          (SARCase.created_date > from_date) & \n",
    "                          (SARCase.created_date < to_date)]['customerno'].unique()\n",
    "    # print ('# of SAR customers: {}'.format(len(target_list)))\n",
    "    view_customer['label'] = view_customer.apply(lambda x: 1 if x['customerno'] in target_list else 0, axis=1)\n",
    "    view_customer  = view_customer.set_index('customerno')\n",
    "    view_wiretrans = view_wiretrans.set_index('customerno')\n",
    "    # view_cheqtrans = view_cheqtrans.set_index('customerno')\n",
    "    return view_wiretrans, view_customer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Large transaction times in one month"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing the data in (2017, 8)\n",
      "Processing the data in (2017, 9)\n",
      "Processing the data in (2017, 10)\n",
      "Processing the data in (2017, 11)\n",
      "Processing the data in (2017, 12)\n",
      "Processing the data in (2018, 1)\n",
      "Processing the data in (2018, 2)\n",
      "Processing the data in (2018, 3)\n",
      "Processing the data in (2018, 4)\n",
      "Processing the data in (2018, 5)\n",
      "Processing the data in (2018, 6)\n",
      "Processing the data in (2018, 7)\n",
      "Processing the data in (2018, 8)\n",
      "Processing the data in (2018, 9)\n",
      "Processing the data in (2018, 10)\n",
      "Processing the data in (2018, 11)\n",
      "Processing the data in (2018, 12)\n",
      "Processing the data in (2019, 1)\n",
      "Processing the data in (2019, 2)\n",
      "Processing the data in (2019, 3)\n",
      "Processing the data in (2019, 4)\n",
      "Processing the data in (2019, 5)\n",
      "Processing the data in (2019, 6)\n"
     ]
    }
   ],
   "source": [
    "from_date_ym = DateYM(2017, 8)\n",
    "to_date_ym = DateYM(2019, 6)\n",
    "trans_out = 500000\n",
    "trans_in  = 1000000\n",
    "\n",
    "list_date_seq = list_date_tuples(from_date_ym, to_date_ym)\n",
    "projectors_shape = dict()\n",
    "for i, date_ym in zip(range(len(list_date_seq)), list_date_seq):\n",
    "    print(\"Processing the data in {}\".format(date_ym))\n",
    "    \n",
    "    view_wiretrans, view_customer = fetch_data_by_month(date_ym, trans_offset=1)\n",
    "    view_wiretrans['edge_group'] = view_wiretrans.apply(lambda x: \"{}_{}\".format(x.org_cust, x.bnf_cust), axis=1)\n",
    "    \n",
    "    ## Transact out counts in one month is large than 500,000\n",
    "    Large_TransOut_Count = view_wiretrans[view_wiretrans.WIRE_AMTOT > trans_out].edge_group.value_counts().rename('Large_TransOut_Count')\n",
    "    \n",
    "    ##　WireTrans Out counts in one month\n",
    "    TransOut_Count = view_wiretrans[view_wiretrans.WIRE_AMTOT > 0].edge_group.value_counts().rename('TransOut_Count')\n",
    "    \n",
    "    ##　Transact in total amount per month is large than 1,000,000\n",
    "    Total_Large_TransIn = view_wiretrans[view_wiretrans.WIRE_AMTIN > trans_in].groupby('edge_group').sum()['WIRE_AMTIN'].rename('Total_Large_TransIn')\n",
    "    \n",
    "    ## Total WireTrans Out in one month\n",
    "    Total_WireTrans = view_wiretrans[view_wiretrans.WIRE_AMTOT > 0].groupby('edge_group').sum()['WIRE_AMTOT'].rename('Total_WireTrans')\n",
    "    \n",
    "    ## Total WireTrans Out times in one month\n",
    "    Total_WireTrans_Times = view_wiretrans[view_wiretrans.WIRE_AMTOT > 0].groupby('edge_group').size().rename('Total_WireTrans_Times')\n",
    "    \n",
    "    ## Average WireTrans Out in one month\n",
    "    Average_WireTrans = (Total_WireTrans/Total_WireTrans_Times).rename('Average_WireTrans')\n",
    "    \n",
    "    \n",
    "    \n",
    "    ## WireTrans in more than 8,000, and total amount is more than 60,000,000\n",
    "    WireTransIn_8000 = view_wiretrans[view_wiretrans.WIRE_AMTIN > 8000].groupby('edge_group').sum()\n",
    "    WireTransIn_8000 = WireTransIn_8000['WIRE_AMTIN'][WireTransIn_8000['WIRE_AMTIN']>60000000].to_frame()\n",
    "    WireTransIn_8000['WireTransIn_8000'] = 1\n",
    "    WireTransIn_8000 = WireTransIn_8000['WireTransIn_8000']\n",
    "    \n",
    "    ## 9 months\n",
    "    view_wiretrans, view_customer = fetch_data_by_month(date_ym, trans_offset=9)\n",
    "    view_wiretrans['edge_group'] = view_wiretrans.apply(lambda x: \"{}_{}\".format(x.org_cust, x.bnf_cust), axis=1)\n",
    "    ## WireTrans more than 8,000 in nine months\n",
    "    WireTrans_Out_9mon = view_wiretrans[view_wiretrans.WIRE_AMTOT > 8000].groupby('edge_group').sum()['WIRE_AMTOT'].rename('WireTrans_Out_9mon')\n",
    "    \n",
    "    ## Output\n",
    "    output = pd.concat([Large_TransOut_Count, \n",
    "                        TransOut_Count, \n",
    "                        Total_Large_TransIn, \n",
    "                        Total_WireTrans, \n",
    "                        Total_WireTrans_Times, \n",
    "                        Average_WireTrans,\n",
    "                        WireTransIn_8000,\n",
    "                        WireTrans_Out_9mon], axis=1).fillna(0)\n",
    "    output = pd.concat([pd.DataFrame([idx.split('_') for idx in output.index], index=output.index), output], axis=1)\n",
    "    output.to_csv(\"./Edge_Attribute/Edge_attribue_{}-{}.csv\".format(date_ym[0], date_ym[1]), index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
