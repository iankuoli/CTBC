{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import networkx as nx\n",
    "import pandas as pd\n",
    "import matplotlib as mpl\n",
    "import matplotlib.pyplot as plt\n",
    "import scipy\n",
    "import numpy as np\n",
    "import math\n",
    "import pickle\n",
    "from tqdm import tqdm_notebook\n",
    "from multiprocessing import Pool\n",
    "\n",
    "np.set_printoptions(suppress=True)\n",
    "pd.set_option('display.float_format', lambda x: '%.3f' % x)\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import precision_score, recall_score, f1_score, roc_auc_score\n",
    "\n",
    "import xgboost as xgb\n",
    "from xgboost.sklearn import XGBClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch import optim\n",
    "from torch.utils.data import DataLoader\n",
    "from torch.autograd import Variable\n",
    "from torch.optim.lr_scheduler import ExponentialLR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.cuda.set_device(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model Declaration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class GRU(nn.Module):\n",
    "    def __init__(self, in_dim, out_dim):\n",
    "        super(GRU, self).__init__()\n",
    "        \n",
    "        self.in_dim = in_dim\n",
    "        self.hid1 = 200\n",
    "        self.hid2 = 100\n",
    "        self.rnn = nn.GRU(self.in_dim, self.hid1, num_layers=3, \n",
    "                          bidirectional=True, batch_first=True, dropout=0.3)\n",
    "        self.relu = nn.ReLU()\n",
    "        \n",
    "        self.out1 = nn.Sequential(\n",
    "            nn.Linear(2*self.hid1, 64),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(p=0.4),\n",
    "            \n",
    "            nn.Linear(64, 32),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(p=0.2),\n",
    "            \n",
    "            nn.Linear(32, out_dim),\n",
    "            nn.Sigmoid(),\n",
    "        )\n",
    "    \n",
    "    def forward(self, x):\n",
    "        rnn, hid = self.rnn(x)\n",
    "        return self.out1(self.relu(rnn[:, -1]))\n",
    "        \n",
    "    def get_trainable_parameters(self):\n",
    "        return (param for param in self.parameters() if param.requires_grad)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "class FocalLoss2(nn.Module):\n",
    "    def __init__(self, alpha=0.01, gamma_pos=3, gamma_neg=2, logits=False, reduce=True):\n",
    "        super(FocalLoss2, self).__init__()\n",
    "        self.alpha = alpha\n",
    "        self.gamma_pos = gamma_pos\n",
    "        self.gamma_neg = gamma_neg\n",
    "        self.logits = logits\n",
    "        self.reduce = reduce\n",
    "    \n",
    "    def forward(self, inputs, targets):\n",
    "        if self.logits:\n",
    "            BCE_loss = F.binary_cross_entropy_with_logits(inputs, targets, reduce=False)\n",
    "        else:\n",
    "            BCE_loss = F.binary_cross_entropy(inputs, targets, reduce=False)\n",
    "        pt = torch.exp(-BCE_loss)\n",
    "        gamma_diff = self.gamma_pos - self.gamma_neg\n",
    "        F_loss_pos = self.alpha * targets * (1-pt)**self.gamma_pos * BCE_loss\n",
    "        F_loss_pos = torch.mean(pt)**(-gamma_diff) * F_loss_pos\n",
    "        F_loss_neg = self.alpha * (1 - targets) * (1-pt)**self.gamma_neg * BCE_loss\n",
    "        F_loss = F_loss_pos + F_loss_neg\n",
    "        \n",
    "        avg_F_loss_pos = torch.sum(F_loss_pos) / torch.sum(targets)\n",
    "        avg_F_loss_neg = torch.sum(F_loss_neg) / torch.sum(1-targets)\n",
    "        \n",
    "        if self.reduce:\n",
    "            return torch.mean(F_loss), avg_F_loss_pos, avg_F_loss_neg\n",
    "        else:\n",
    "            return F_loss, F_loss_pos, F_loss_neg"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Parameters Settings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#\n",
    "# Classifier\n",
    "# ---------------------\n",
    "## focal loss\n",
    "alpha = 1\n",
    "gamma_pos = 6\n",
    "gamma_neg = 2\n",
    "learn_rate = 1e-5\n",
    "grad_clip = 1\n",
    "\n",
    "#\n",
    "# VAT\n",
    "# ---------------------\n",
    "vat_xi = 1e-6\n",
    "vat_eps_pos = 1\n",
    "vat_eps_neg = 0.01\n",
    "vat_ip = 1\n",
    "\n",
    "#\n",
    "# Training process\n",
    "# ---------------------\n",
    "train_batch_size = 128\n",
    "test_batch_size = 256\n",
    "\n",
    "max_epochs = 100"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Preparation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data = np.load('../datasets/Training_data_heter.npz', allow_pickle=True)\n",
    "test_data  = np.load('../datasets/Testing_data_heter.npz',  allow_pickle=True)\n",
    "\n",
    "training_data, training_label, training_announce, training_FILTER = train_data['arr_0'], train_data['arr_1'], train_data['arr_2'], train_data['arr_3']\n",
    "testing_data,  testing_label,  testing_announce,  testing_FILTER = test_data['arr_0'], test_data['arr_1'], test_data['arr_2'], test_data['arr_3']\n",
    "\n",
    "X_train = training_data#[(training_announce == 1) & (training_FILTER == 0 )]\n",
    "y_train = training_label#[(training_announce == 1) & (training_FILTER == 0 )]\n",
    "\n",
    "X_test  = testing_data#[(testing_announce == 1) & (testing_FILTER == 0 )]\n",
    "y_test  = testing_label#[(testing_announce == 1) & (testing_FILTER == 0 )]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "68927.0"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(test_data)/7"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([3, 661])"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_data[0][0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# data = np.load('GRUArray_and_label_for_NewEmbedding_heter_superv_recur_focal_logisticMF.npz', allow_pickle=True)\n",
    "\n",
    "# GPUArray = data['arr_0']\n",
    "# label = data['arr_1']\n",
    "\n",
    "# GPUArray = GPUArray[-1033905:,:,:]\n",
    "# label = label[-1033905:]\n",
    "\n",
    "# X_train, X_test, y_train, y_test = train_test_split(GPUArray, label, random_state=42)\n",
    "X_train = torch.FloatTensor(X_train)\n",
    "X_test = torch.FloatTensor(X_test)\n",
    "y_train = torch.FloatTensor(y_train)\n",
    "y_test = torch.FloatTensor(y_test)\n",
    "\n",
    "train_data = []\n",
    "for i in range(len(X_train)):\n",
    "    train_data.append((X_train[i], y_train[i]))\n",
    "    \n",
    "test_data = []\n",
    "for i in range(len(X_test)):\n",
    "    test_data.append((X_test[i], y_test[i]))\n",
    "\n",
    "train_dataloader = DataLoader(train_data, shuffle=True, batch_size=train_batch_size)\n",
    "test_dataloader = DataLoader(test_data, shuffle=False, batch_size=test_batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "classifier = GRU(in_dim=X_train.shape[2], out_dim=2).cuda()\n",
    "focal_loss = FocalLoss2(alpha, gamma_pos, gamma_neg)\n",
    "# optim_clsfr = optim.Adam(filter(lambda p: p.requires_grad, classifier.parameters()), \n",
    "#                          lr=learn_rate)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Predict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plotting(pred_y_list, label_list, PATH):\n",
    "    ###########################################################\n",
    "    plt.ylabel('Count(log)')\n",
    "    plt.xlabel('Score')\n",
    "    plt.yscale('log')\n",
    "    \n",
    "    ax = plt.gca()\n",
    "    ax.spines['right'].set_color('none')\n",
    "    ax.spines['top'].set_color('none')\n",
    "    ax.spines['left'].set_color('none')\n",
    "    ax.spines['bottom'].set_color('none')\n",
    "    \n",
    "    plt.grid(color = '#9999CC')\n",
    "    plt.hist(np.array(pred_y_list)[np.where(np.array(label_list) == 0)], \n",
    "             bins=[n/200 for n in range(50, 150)], \n",
    "             label='Negative',\n",
    "             color='#598987')\n",
    "    plt.hist(np.array(pred_y_list)[np.where(np.array(label_list) == 1)], \n",
    "             bins=[n/200 for n in range(50, 150)], \n",
    "             label='Positive', \n",
    "             color='#FFD000')\n",
    "    plt.legend(loc='upper right')\n",
    "    plt.savefig(\"{}_test_1.jpg\".format(PATH.split('/')[-1]), dpi=1000, quality=100)\n",
    "    plt.show()\n",
    "    ###########################################################\n",
    "    plt.ylabel('Log Count')\n",
    "    plt.xlabel('Score')\n",
    "    plt.yscale('log')\n",
    "    \n",
    "    ax = plt.gca()\n",
    "    ax.spines['right'].set_color('none')\n",
    "    ax.spines['top'].set_color('none')\n",
    "    ax.spines['left'].set_color('none')\n",
    "    ax.spines['bottom'].set_color('none')\n",
    "    \n",
    "    plt.grid(color = '#9999CC')\n",
    "    plt.hist(np.array(pred_y_list)[np.where(np.array(label_list) == 0)], \n",
    "             bins=[n/2000 for n in range(530, 600)], \n",
    "             label='Negative', \n",
    "             color='#598987')\n",
    "    plt.hist(np.array(pred_y_list)[np.where(np.array(label_list) == 1)], \n",
    "             bins=[n/2000 for n in range(530, 600)], \n",
    "             label='Positive', \n",
    "             color='#FFD000')\n",
    "    plt.legend(loc='upper right')\n",
    "    plt.savefig(\"{}_test_2.jpg\".format(PATH.split('/')[-1]), dpi=1000, quality=100)\n",
    "    plt.show()\n",
    "\n",
    "def func(PATH, thres):\n",
    "    optimizer = optim.Adam(filter(lambda p: p.requires_grad, classifier.parameters()), lr=learn_rate)\n",
    "\n",
    "    model = GRU(in_dim=X_train.shape[2], out_dim=2).cuda()\n",
    "    checkpoint = torch.load(PATH)\n",
    "    model.load_state_dict(checkpoint['model_state_dict'])\n",
    "    optimizer.load_state_dict(checkpoint['optimizer_state_dict'])\n",
    "    epoch = checkpoint['epoch']\n",
    "    loss = checkpoint['loss']\n",
    "\n",
    "    model.eval()\n",
    "\n",
    "    label_list = []\n",
    "    pred_y_list = []\n",
    "\n",
    "    for batch_idx, (data, target) in tqdm_notebook(enumerate(test_dataloader)):\n",
    "        if data.size()[0] != test_dataloader.batch_size:\n",
    "            continue\n",
    "        data, target = Variable(data.cuda()), Variable(target.cuda())\n",
    "        # Update classifier\n",
    "\n",
    "        pred_y = model(data).squeeze(-1)\n",
    "        pred_y = torch.nn.functional.softmax(pred_y, dim=1)[:, 1]\n",
    "\n",
    "        label_list += list(target.cpu().detach().numpy())\n",
    "        pred_y_list += list(pred_y.cpu().detach().numpy())\n",
    "    \n",
    "    # thres = sorted(np.array(pred_y_list)[np.where(np.array(label_list) == 0)])[int(len(pred_y_list)*0.997)]\n",
    "    \n",
    "    print(\"Testing Treshold: {}\".format(np.min(np.array(pred_y_list)[np.where(np.array(label_list) == 1)])))\n",
    "    print(\"Total Positve: {}\".format(len(np.where(np.array(label_list) == 1)[0])))\n",
    "    print(\"Total Candidate: {}\".format(np.sum(pred_y_list >= np.min(np.array(pred_y_list)[np.where(np.array(label_list) == 1)]))))\n",
    "    print(\"Negative Mean: {}\".format(np.array(pred_y_list)[np.where(np.array(label_list) == 0)].mean()))\n",
    "    print(\"Negative Variance: {}\".format(np.array(pred_y_list)[np.where(np.array(label_list) == 0)].std()))\n",
    "    print(\"Negative Q997: {}\".format(sorted(np.array(pred_y_list)[np.where(np.array(label_list) == 0)])[int(len(pred_y_list)*0.997)]))\n",
    "    print(\"Prec: {}\".format(np.sum(np.array(label_list)[np.where(np.array(pred_y_list) > thres)])/np.sum(np.array(pred_y_list) > thres) ))\n",
    "    \n",
    "    #     plotting(pred_y_list, label_list, PATH)\n",
    "    # plotting(pred_y_list, label_list, PATH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "76cce78093354c4fa17ee289114eca55",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=1.0, bar_style='info', max=1.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Testing Treshold: 0.2693917751312256\n",
      "Total Positve: 46\n",
      "Total Candidate: 1372\n",
      "Negative Mean: 0.2689572870731354\n",
      "Negative Variance: 0.0004295199760235846\n",
      "Negative Q997: 0.269335001707077\n",
      "Prec: 0.02804878048780488\n"
     ]
    }
   ],
   "source": [
    "PATH = 'saved_models/VATGRU_heter_clsfr_xi6_eps03_focal42_BestAUC_1'\n",
    "func(PATH, 0.26920807361602783)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a10c24cfb80f4e56872a2fa986eb70b3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=1.0, bar_style='info', max=1.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Testing Treshold: 0.2690467834472656\n",
      "Total Positve: 46\n",
      "Total Candidate: 1315\n",
      "Negative Mean: 0.268947571516037\n",
      "Negative Variance: 0.0001918014750117436\n",
      "Negative Q997: 0.26901817321777344\n",
      "Prec: 0.027577937649880094\n"
     ]
    }
   ],
   "source": [
    "PATH = 'saved_models/VATGRU_heter_clsfr_xi6_eps03_focal42_BestAUC_2'\n",
    "func(PATH, 0.26898202300071716)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1a4fa54a9bcb4b5888a943ece91903cf",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=1.0, bar_style='info', max=1.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Testing Treshold: 0.2691945731639862\n",
      "Total Positve: 46\n",
      "Total Candidate: 1254\n",
      "Negative Mean: 0.26895132660865784\n",
      "Negative Variance: 0.00034796789987012744\n",
      "Negative Q997: 0.26911211013793945\n",
      "Prec: 0.028065893837705917\n"
     ]
    }
   ],
   "source": [
    "PATH = 'saved_models/VATGRU_heter_clsfr_xi6_eps03_focal42_BestAUC_3'\n",
    "func(PATH, 0.26902028918266296)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1dda81dbfecf4d7ab4c409179488da6d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=1.0, bar_style='info', max=1.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Testing Treshold: 0.2692015469074249\n",
      "Total Positve: 46\n",
      "Total Candidate: 1164\n",
      "Negative Mean: 0.26894959807395935\n",
      "Negative Variance: 0.0002595408004708588\n",
      "Negative Q997: 0.26909157633781433\n",
      "Prec: 0.0283775447254781\n"
     ]
    }
   ],
   "source": [
    "PATH = 'saved_models/VATGRU_heter_clsfr_xi6_eps03_focal42_BestAUC_4'\n",
    "func(PATH, 0.2690264582633972)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5e30129edfce4bb0a67f8a8b93f6a450",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=1.0, bar_style='info', max=1.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Testing Treshold: 0.269040584564209\n",
      "Total Positve: 46\n",
      "Total Candidate: 1520\n",
      "Negative Mean: 0.2689470648765564\n",
      "Negative Variance: 0.00015061203157529235\n",
      "Negative Q997: 0.269059419631958\n",
      "Prec: 0.02857142857142857\n"
     ]
    }
   ],
   "source": [
    "PATH = 'saved_models/VATGRU_heter_clsfr_xi6_eps03_focal42_BestAUC_5'\n",
    "func(PATH, 0.2690237760543823)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1:\n",
    "    Training Treshold: 0.3381294740905762\n",
    "    Testing Treshold: 0.2693917751312256\n",
    "    Total Positve: 46\n",
    "    Total Candidate: 1372  \n",
    "    Precision: 3.36%\n",
    "\n",
    "2: \n",
    "    Training Treshold: 0.38438619511032107\n",
    "    Testing Treshold: 0.2690467834472656\n",
    "    Total Positve: 46\n",
    "    Total Candidate: 1315\n",
    "    Precision: 3.50%\n",
    "\n",
    "3:\n",
    "    Training Treshold: 0.3429013325443268\n",
    "    Testing Treshold: 0.2691945731639862\n",
    "    Total Positve: 46\n",
    "    Total Candidate: 1254\n",
    "    Precision: 3.67%\n",
    "\n",
    "4:\n",
    "    Training Treshold: 0.33618862764739993\n",
    "    Testing Treshold: 0.2692015469074249\n",
    "    Total Positve: 46\n",
    "    Total Candidate: 1164\n",
    "    Precision: 3.94%\n",
    "\n",
    "5:\n",
    "    Training Treshold: 0.31790391938591006\n",
    "    Testing Treshold: 0.269040584564209\n",
    "    Total Positve: 46\n",
    "    Total Candidate: 1520\n",
    "    Precision: 3.03%"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
